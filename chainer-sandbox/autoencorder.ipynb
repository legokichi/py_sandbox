{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import Variable, optimizers, Chain, cuda\n",
    "import data\n",
    "import pickle\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = data.load_mnist_data()\n",
    "x_all = mnist[\"data\"].astype(np.float32) / 255\n",
    "y_all = mnist[\"target\"].astype(np.int32)\n",
    "x_train, x_test = np.split(x_all, [60000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model(Chain):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__(\n",
    "            l1=L.Linear(784, 400),\n",
    "            l1b=L.Linear(400, 784),\n",
    "            l2=L.Linear(400, 100),\n",
    "            l2b=L.Linear(100, 400),\n",
    "            l3=L.Linear(100, 49),\n",
    "            l3b=L.Linear(49, 100),\n",
    "            l4=L.Linear(49, 16),\n",
    "            l4b=L.Linear(16, 49),\n",
    "            l5=L.Linear(16, 3),\n",
    "            l5b=L.Linear(3, 16) )\n",
    "    def __call__(self, x, train=True, layer=0):\n",
    "        tf = [False]\n",
    "        for i in range(6):\n",
    "            if i < layer-1: tf.append(False)\n",
    "            else:               tf.append(train)\n",
    "        # chainer は Variable しないと関数が chain してしまう\n",
    "        x=Variable(x.data); h = F.dropout(F.relu(self.l1(x)), train=tf[1]);\n",
    "        if layer == 1: return F.dropout(self.l1b(h), train=train), x\n",
    "        x=Variable(h.data); h = F.dropout(F.relu(self.l2(x)), train=tf[2]);\n",
    "        if layer == 2: return F.dropout(self.l2b(h), train=train), x\n",
    "        x=Variable(h.data); h = F.dropout(F.relu(self.l3(x)), train=tf[3]);\n",
    "        if layer == 3: return F.dropout(self.l3b(h), train=train), x\n",
    "        x=Variable(h.data); h = F.dropout(F.relu(self.l4(x)), train=tf[4]);\n",
    "        if layer == 4: return F.dropout(self.l4b(h), train=train), x\n",
    "        x=Variable(h.data); h = F.dropout(F.relu(self.l5(x)), train=tf[5]);\n",
    "        if layer == 5: return F.dropout(self.l5b(h), train=train), x\n",
    "        return x\n",
    "    def finetune(self, x, train=True):\n",
    "        h = F.dropout(F.relu(self.l1(x)), train=False)\n",
    "        h = F.dropout(F.relu(self.l1(h)), train=False)\n",
    "        h = F.dropout(F.relu(self.l1(h)), train=True)\n",
    "        h = F.dropout(F.relu(self.l1(h)), train=True)\n",
    "        h = F.dropout(F.relu(self.l1(h)), train=True)\n",
    "        return F.dropout(F.relu(self.l6(h)), train=True)\n",
    "    def dump(self):\n",
    "        pickle.dump(self.l1, io.open(\"l1.pkl\", \"wb\"))\n",
    "        pickle.dump(self.l2, io.open(\"l2.pkl\", \"wb\"))\n",
    "        pickle.dump(self.l3, io.open(\"l3.pkl\", \"wb\"))\n",
    "        pickle.dump(self.l4, io.open(\"l4.pkl\", \"wb\"))\n",
    "        pickle.dump(self.l5, io.open(\"l5.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if gpu\n",
    "xp=np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.MomentumSGD(lr=0.01, momentum=0.9)\n",
    "optimizer.setup(model)\n",
    "batchsize = 100\n",
    "datasize = 60000\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 1 0 0.10275529325008392\n",
      "layer: 2 0 0.0005041405675001442\n",
      "layer: 3 0 7.114500476745889e-05\n",
      "layer: 4 0 8.6892832769081e-06\n",
      "layer: 5 0 1.0151077276532305e-06\n"
     ]
    }
   ],
   "source": [
    "for layer in range(1, 6):\n",
    "    optimizer.setup(model)\n",
    "    for j in range(epochs):\n",
    "        indexes = np.random.permutation(datasize)\n",
    "        for i in range(0, datasize, batchsize):\n",
    "            x = Variable(xp.asarray(x_train[indexes[i: i+batchsize]]))\n",
    "            model.zerograds()\n",
    "            img,x = model(x, layer=layer)\n",
    "            loss = F.mean_squared_error(img, x)\n",
    "            loss.backward()\n",
    "            optimizer.update()\n",
    "    x = Variable(xp.asarray(x_test))\n",
    "    img, x = model(x, train=False, layer=layer)\n",
    "    loss = F.mean_squared_error(img, x)\n",
    "    print(\"layer:\", layer, j, loss.data)\n",
    "    model.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
