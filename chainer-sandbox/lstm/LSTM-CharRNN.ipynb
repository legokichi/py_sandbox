{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer.functions as F\n",
    "from chainer import Variable, FunctionSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CharRNN(FunctionSet):\n",
    "    def __init__(self, n_vocab, n_units):\n",
    "        # 最新の chainer では ここで lstm 定義できるよ\n",
    "        super(CharRNN, self).__init__(\n",
    "            embed = F.EmbedID(n_vocab, n_units),\n",
    "            l1_x=F.Linear(n_units, 4*n_units),\n",
    "            l1_h=F.Linear(n_units, 4*n_units),\n",
    "            l2_x=F.Linear(n_units, 4*n_units),\n",
    "            l2_h=F.Linear(n_units, 4*n_units),\n",
    "            l3_x=F.Linear(n_units, 4*n_units),\n",
    "            l3_h=F.Linear(n_units, 4*n_units),\n",
    "            l4_x=F.Linear(n_units, 4*n_units),\n",
    "            l4_h=F.Linear(n_units, 4*n_units),\n",
    "            l5_x=F.Linear(n_units, 4*n_units),\n",
    "            l5_h=F.Linear(n_units, 4*n_units),\n",
    "            l6=F.Linear(n_units, n_vocab) )\n",
    "        for param in self.parameters:\n",
    "            param[:] = np.random.uniform(-0.08, 0.08, param.shape)\n",
    "    def forward_one_step(self, x_data, y_data, state, train=True, dropout_ratio=0.5):\n",
    "        x = Variable(x_data, volatile=not train)\n",
    "        t = Variable(x_data, volatile=not train)\n",
    "        h0 = self.embed(x)\n",
    "        # ci, hi などは lstm セルの要素\n",
    "        h1_in = self.l1_x(F.dropout(h0, ratio=dropout_ratio, train = train)) + self.l1_h(state[\"h1\"]); c1, h1 = F.lstm(state[\"c1\"], h1_in)\n",
    "        h2_in = self.l2_x(F.dropout(h1, ratio=dropout_ratio, train = train)) + self.l2_h(state[\"h2\"]); c2, h2 = F.lstm(state[\"c2\"], h2_in)\n",
    "        h3_in = self.l3_x(F.dropout(h3, ratio=dropout_ratio, train = train)) + self.l3_h(state[\"h3\"]); c3, h3 = F.lstm(state[\"c3\"], h3_in)\n",
    "        h4_in = self.l4_x(F.dropout(h4, ratio=dropout_ratio, train = train)) + self.l4_h(state[\"h4\"]); c4, h4 = F.lstm(state[\"c4\"], h4_in)\n",
    "        h5_in = self.l5_x(F.dropout(h5, ratio=dropout_ratio, train = train)) + self.l5_h(state[\"h5\"]); c5, h5 = F.lstm(state[\"c5\"], h5_in)\n",
    "        state = {\n",
    "            \"c1\":c1, \"h1\":h1,\n",
    "            \"c2\":c2, \"h2\":h2,\n",
    "            \"c3\":c3, \"h3\":h3,\n",
    "            \"c4\":c4, \"h4\":h4,\n",
    "            \"c5\":c5, \"h5\":h5 }\n",
    "        return state, F.softmax_cross_entropy(y, t)\n",
    "    def predict(self, x_data, state):\n",
    "        x = Variable(x_data, volatile=True)\n",
    "        h0 = self.embed(x);\n",
    "        h1_in = self.l1_x(h0) + self.l1_h(state[\"h1\"]); c1, h1 = F.lstm(state[\"c1\", h1_in])\n",
    "        h2_in = self.l2_x(h1) + self.l2_h(state[\"h2\"]); c2, h2 = F.lstm(state[\"c2\", h2_in])\n",
    "        h3_in = self.l3_x(h2) + self.l3_h(state[\"h3\"]); c3, h3 = F.lstm(state[\"c3\", h3_in])\n",
    "        h4_in = self.l4_x(h3) + self.l4_h(state[\"h4\"]); c4, h4 = F.lstm(state[\"c4\", h4_in])\n",
    "        h5_in = self.l5_x(h4) + self.l5_h(state[\"h5\"]); c5, h5 = F.lstm(state[\"c5\", h5_in])\n",
    "        y = self.l6(h5)\n",
    "        state = {\n",
    "            \"c1\":c1, \"h1\":h1,\n",
    "            \"c2\":c2, \"h2\":h2,\n",
    "            \"c3\":c3, \"h3\":h3,\n",
    "            \"c4\":c4, \"h4\":h4,\n",
    "            \"c5\":c5, \"h5\":h5 }\n",
    "        return state, F.softmax(y)\n",
    "def make_initial_state(n_units, batchsize=0, train=True):\n",
    "    return {\n",
    "        name:\n",
    "            Variable(\n",
    "                        np.zeros((batchsize, n_units),\n",
    "                        dtype=np.float32),\n",
    "                        volatile=not tarin\n",
    "            ) for name in (\n",
    "                \"c1\", \"h1\",\n",
    "                \"c2\", \"h2\",\n",
    "                \"c3\", \"h3\",\n",
    "                \"c4\", \"h4\",\n",
    "                \"c5\", \"h5\") }\n",
    "'''\n",
    ">>>{name: 0 for name in (\"c1\", \"h1\",\"c2\", \"h2\",\"c3\",\"h3\",\"c4\", \"h4\",\"c5\", \"h5\") }\n",
    "{'c1': 0,\n",
    " 'c2': 0,\n",
    " 'c3': 0,\n",
    " 'c4': 0,\n",
    " 'c5': 0,\n",
    " 'h1': 0,\n",
    " 'h2': 0,\n",
    " 'h3': 0,\n",
    " 'h4': 0,\n",
    " 'h5': 0}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c1': 0,\n",
       " 'c2': 0,\n",
       " 'c3': 0,\n",
       " 'c4': 0,\n",
       " 'c5': 0,\n",
       " 'h1': 0,\n",
       " 'h2': 0,\n",
       " 'h3': 0,\n",
       " 'h4': 0,\n",
       " 'h5': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
